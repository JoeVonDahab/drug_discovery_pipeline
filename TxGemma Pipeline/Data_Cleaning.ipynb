{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7e6ad6d",
   "metadata": {},
   "source": [
    "# Load Dataset and Clean It"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bd1a8c",
   "metadata": {},
   "source": [
    "## Known Binders to Q99814 · EPAS1 (taken from BindingDB curated by UCSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaf49be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Known_HIF_Binders.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aead96",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = df[[\"Ligand SMILES\", \"IC50 (nM)\"]].dropna()\n",
    "\n",
    "# remove rows that contain '<' or '>'\n",
    "has_censor = clean_df[\"IC50 (nM)\"] \\\n",
    "    .astype(str) \\\n",
    "    .str.contains(r\"[<>]\")\n",
    "\n",
    "# count how many rows will be dropped\n",
    "dropped_count = has_censor.sum()\n",
    "print(f\"Dropping {dropped_count} rows with '<' or '>' in IC50\")\n",
    "\n",
    "# keep only the rows *without* '<' or '>'\n",
    "clean_df = clean_df.loc[~has_censor].reset_index(drop=True)\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eebcb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, Crippen, Lipinski\n",
    "\n",
    "# Clean & standardize IC50, compute pIC50\n",
    "def parse_ic50_to_pic50(ic50_str):\n",
    "    s = str(ic50_str).strip()\n",
    "    try:\n",
    "        nm = float(s)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "    # convert nM → M\n",
    "    m = nm * 1e-9\n",
    "    # compute pIC50\n",
    "    pic50 = -np.log10(m)\n",
    "    return pic50\n",
    "\n",
    "clean_df[\"pIC50\"] = clean_df[\"IC50 (nM)\"].apply(parse_ic50_to_pic50)\n",
    "\n",
    "# Bin into activity classes\n",
    "# strong binder if pIC50 ≥ 7 (IC50 ≤ 100 nM), else weak/non-binder\n",
    "threshold = 7.0\n",
    "clean_df[\"activity_class\"] = np.where(clean_df[\"pIC50\"] >= threshold, \"strong\", \"weak\")\n",
    "\n",
    "# Compute 2D descriptors via RDKit\n",
    "def compute_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return {\n",
    "            \"MolWt\": np.nan,\n",
    "            \"TPSA\": np.nan,\n",
    "            \"HBD\": np.nan,\n",
    "            \"HBA\": np.nan,\n",
    "            \"RotBonds\": np.nan,\n",
    "            \"LogP\": np.nan,\n",
    "        }\n",
    "    return {\n",
    "        \"MolWt\": Descriptors.MolWt(mol),\n",
    "        \"TPSA\": Descriptors.TPSA(mol),\n",
    "        \"HBD\": Lipinski.NumHDonors(mol),\n",
    "        \"HBA\": Lipinski.NumHAcceptors(mol),\n",
    "        \"RotBonds\": Descriptors.NumRotatableBonds(mol),\n",
    "        \"LogP\": Crippen.MolLogP(mol),\n",
    "    }\n",
    "\n",
    "# apply and expand into separate columns\n",
    "desc_df = clean_df[\"Ligand SMILES\"].apply(compute_descriptors).apply(pd.Series)\n",
    "clean_df = pd.concat([clean_df, desc_df], axis=1)\n",
    "clean_df[\"is_known_binder\"] = True\n",
    "\n",
    "# View the table\n",
    "print(clean_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3dcf12",
   "metadata": {},
   "source": [
    "## Duds (Taken from BindingDB on Compounds that Bind to ESR1 · P03372)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccdff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ESR1_Binders.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c7bb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "esr1_df = df[[\"Ligand SMILES\", \"IC50 (nM)\"]].dropna()\n",
    "\n",
    "# remove rows that contain '<' or '>'\n",
    "has_censor = esr1_df[\"IC50 (nM)\"] \\\n",
    "    .astype(str) \\\n",
    "    .str.contains(r\"[<>]\")\n",
    "\n",
    "# count how many rows will be dropped\n",
    "dropped_count = has_censor.sum()\n",
    "print(f\"Dropping {dropped_count} rows with '<' or '>' in IC50\")\n",
    "\n",
    "# keep only the rows *without* '<' or '>'\n",
    "esr1_df = esr1_df.loc[~has_censor].reset_index(drop=True)\n",
    "esr1_df.reset_index(drop=True, inplace=True)\n",
    "esr1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ecfb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "esr1_df[\"pIC50\"] = esr1_df[\"IC50 (nM)\"].apply(parse_ic50_to_pic50)\n",
    "\n",
    "esr1_df[\"activity_class\"] = np.where(esr1_df[\"pIC50\"] >= threshold, \"strong\", \"weak\")\n",
    "\n",
    "\n",
    "# apply and expand into separate columns\n",
    "temp_df = esr1_df[\"Ligand SMILES\"].apply(compute_descriptors).apply(pd.Series)\n",
    "esr1_df = pd.concat([esr1_df, temp_df], axis=1)\n",
    "esr1_df[\"is_known_binder\"] = False\n",
    "\n",
    "\n",
    "print(esr1_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1de892",
   "metadata": {},
   "source": [
    "## Joining the known and unknown binders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd77570",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_binders = pd.concat([clean_df, esr1_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef7caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix up dataset to avoid patterns\n",
    "perm = np.random.permutation(len(all_binders))\n",
    "all_binders = all_binders.iloc[perm].reset_index(drop=True)\n",
    "\n",
    "all_binders.to_csv(\"all_binders.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc629bc1",
   "metadata": {},
   "source": [
    "## Turning CSV to jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf4b94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_binders = pd.read_csv(\"all_binders.csv\")\n",
    "\n",
    "test = all_binders.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40285eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def make_example(row):\n",
    "    prompt = (\n",
    "        \"From the following information about a ligand, predict whether it can bind to the HIF-2α protein.\\n\\n\"\n",
    "        f\"This ligand is represented by the SMILES string {row['Ligand SMILES']}, and exhibits an IC50 of \"\n",
    "        f\"{row['IC50 (nM)']} nM (pIC50 = {row['pIC50']:.2f}). It has a molecular weight of {row['MolWt']:.2f} Da, \"\n",
    "        f\"a topological polar surface area of {row['TPSA']:.2f} Å², {row['HBD']} hydrogen bond donor\"\n",
    "        f\"{'s' if row['HBD'] != 1 else ''}, {row['HBA']} hydrogen bond acceptor\"\n",
    "        f\"{'s' if row['HBA'] != 1 else ''}, and {row['RotBonds']} rotatable bond\"\n",
    "        f\"{'s' if row['RotBonds'] != 1 else ''}, with a logP of {row['LogP']:.2f}.\\n\"\n",
    "    )\n",
    "    completion = \"Answer: Yes, it binds to HIF-2α<eos>\" if row[\"is_known_binder\"] else \"Answer: No, it doesn't bind to HIF-2α<eos>\"\n",
    "    return {\"prompt\": prompt, \"bind\": completion}\n",
    "\n",
    "\n",
    "with open(\"train_hif_binding.jsonl\",\"w\") as fout:\n",
    "    for _, row in all_binders.iterrows():\n",
    "        ex = make_example(row)\n",
    "        fout.write(json.dumps(ex) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
