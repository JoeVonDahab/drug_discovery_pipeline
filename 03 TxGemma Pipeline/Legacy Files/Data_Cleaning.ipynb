{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c7e6ad6d",
      "metadata": {
        "id": "c7e6ad6d"
      },
      "source": [
        "# Load Dataset and Clean It"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run this notebook, are you required to have 2 csv files: Known_HIF_Binders.csv and ESR1_Binders.csv. These files can be downloaded off BindingDB. I chose to use the ESR1 binders as a dud because none of the bona-fide HIF-2α small‐molecule ligands have been shown to appreciably bind estrogen receptor α (ESR1) at concentrations relevant for their on‐target activity. The UNIPROT ID of HIF-2α is Q99814 and ESR1 is P03372."
      ],
      "metadata": {
        "id": "Cc6JMDzTRjdw"
      },
      "id": "Cc6JMDzTRjdw"
    },
    {
      "cell_type": "markdown",
      "id": "19bd1a8c",
      "metadata": {
        "id": "19bd1a8c"
      },
      "source": [
        "## Known Binders to Q99814 · EPAS1 (taken from BindingDB curated by UCSD)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "id": "kEOkY6xHNaZq"
      },
      "id": "kEOkY6xHNaZq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efaf49be",
      "metadata": {
        "id": "efaf49be"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"Known_HIF_Binders.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7aead96",
      "metadata": {
        "id": "d7aead96"
      },
      "outputs": [],
      "source": [
        "clean_df = df[[\"Ligand SMILES\", \"IC50 (nM)\"]].dropna()\n",
        "\n",
        "# remove rows that contain '<' or '>'\n",
        "has_censor = clean_df[\"IC50 (nM)\"] \\\n",
        "    .astype(str) \\\n",
        "    .str.contains(r\"[<>]\")\n",
        "\n",
        "# count how many rows will be dropped\n",
        "dropped_count = has_censor.sum()\n",
        "print(f\"Dropping {dropped_count} rows with '<' or '>' in IC50\")\n",
        "\n",
        "# keep only the rows *without* '<' or '>'\n",
        "clean_df = clean_df.loc[~has_censor].reset_index(drop=True)\n",
        "clean_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eebcb89",
      "metadata": {
        "id": "8eebcb89"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors, Crippen, Lipinski\n",
        "\n",
        "# Clean & standardize IC50, compute pIC50\n",
        "def parse_ic50_to_pic50(ic50_str):\n",
        "    s = str(ic50_str).strip()\n",
        "    try:\n",
        "        nm = float(s)\n",
        "    except ValueError:\n",
        "        return np.nan\n",
        "\n",
        "    # convert nM → M\n",
        "    m = nm * 1e-9\n",
        "    # compute pIC50\n",
        "    pic50 = -np.log10(m)\n",
        "    return pic50\n",
        "\n",
        "clean_df[\"pIC50\"] = clean_df[\"IC50 (nM)\"].apply(parse_ic50_to_pic50)\n",
        "\n",
        "# Bin into activity classes\n",
        "# strong binder if pIC50 ≥ 7 (IC50 ≤ 100 nM), else weak/non-binder\n",
        "threshold = 7.0\n",
        "clean_df[\"activity_class\"] = np.where(clean_df[\"pIC50\"] >= threshold, \"strong\", \"weak\")\n",
        "\n",
        "# Compute 2D descriptors via RDKit\n",
        "def compute_descriptors(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return {\n",
        "            \"MolWt\": np.nan,\n",
        "            \"TPSA\": np.nan,\n",
        "            \"HBD\": np.nan,\n",
        "            \"HBA\": np.nan,\n",
        "            \"RotBonds\": np.nan,\n",
        "            \"LogP\": np.nan,\n",
        "        }\n",
        "    return {\n",
        "        \"MolWt\": Descriptors.MolWt(mol),\n",
        "        \"TPSA\": Descriptors.TPSA(mol),\n",
        "        \"HBD\": Lipinski.NumHDonors(mol),\n",
        "        \"HBA\": Lipinski.NumHAcceptors(mol),\n",
        "        \"RotBonds\": Descriptors.NumRotatableBonds(mol),\n",
        "        \"LogP\": Crippen.MolLogP(mol),\n",
        "    }\n",
        "\n",
        "# apply and expand into separate columns\n",
        "desc_df = clean_df[\"Ligand SMILES\"].apply(compute_descriptors).apply(pd.Series)\n",
        "clean_df = pd.concat([clean_df, desc_df], axis=1)\n",
        "clean_df[\"is_known_binder\"] = True\n",
        "\n",
        "# View the table\n",
        "print(clean_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d3dcf12",
      "metadata": {
        "id": "4d3dcf12"
      },
      "source": [
        "## Duds (Taken from BindingDB on Compounds that Bind to ESR1 · P03372)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ccdff67",
      "metadata": {
        "id": "0ccdff67"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"ESR1_Binders.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30c7bb62",
      "metadata": {
        "id": "30c7bb62"
      },
      "outputs": [],
      "source": [
        "esr1_df = df[[\"Ligand SMILES\", \"IC50 (nM)\"]].dropna()\n",
        "\n",
        "# remove rows that contain '<' or '>'\n",
        "has_censor = esr1_df[\"IC50 (nM)\"] \\\n",
        "    .astype(str) \\\n",
        "    .str.contains(r\"[<>]\")\n",
        "\n",
        "# count how many rows will be dropped\n",
        "dropped_count = has_censor.sum()\n",
        "print(f\"Dropping {dropped_count} rows with '<' or '>' in IC50\")\n",
        "\n",
        "# keep only the rows *without* '<' or '>'\n",
        "esr1_df = esr1_df.loc[~has_censor].reset_index(drop=True)\n",
        "esr1_df.reset_index(drop=True, inplace=True)\n",
        "esr1_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8ecfb63",
      "metadata": {
        "id": "e8ecfb63"
      },
      "outputs": [],
      "source": [
        "esr1_df[\"pIC50\"] = esr1_df[\"IC50 (nM)\"].apply(parse_ic50_to_pic50)\n",
        "\n",
        "esr1_df[\"activity_class\"] = np.where(esr1_df[\"pIC50\"] >= threshold, \"strong\", \"weak\")\n",
        "\n",
        "\n",
        "# apply and expand into separate columns\n",
        "temp_df = esr1_df[\"Ligand SMILES\"].apply(compute_descriptors).apply(pd.Series)\n",
        "esr1_df = pd.concat([esr1_df, temp_df], axis=1)\n",
        "esr1_df[\"is_known_binder\"] = False\n",
        "\n",
        "\n",
        "print(esr1_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae1de892",
      "metadata": {
        "id": "ae1de892"
      },
      "source": [
        "## Joining the known and unknown binders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fd77570",
      "metadata": {
        "id": "9fd77570"
      },
      "outputs": [],
      "source": [
        "all_binders = pd.concat([clean_df, esr1_df], axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ef7caf1",
      "metadata": {
        "id": "9ef7caf1"
      },
      "outputs": [],
      "source": [
        "# mix up dataset to avoid patterns\n",
        "perm = np.random.permutation(len(all_binders))\n",
        "all_binders = all_binders.iloc[perm].reset_index(drop=True)\n",
        "\n",
        "all_binders.to_csv(\"all_binders.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc629bc1",
      "metadata": {
        "id": "fc629bc1"
      },
      "source": [
        "## Turning CSV to jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cf4b94a",
      "metadata": {
        "id": "1cf4b94a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "all_binders = pd.read_csv(\"all_binders.csv\")\n",
        "\n",
        "test = all_binders.head(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40285eb9",
      "metadata": {
        "id": "40285eb9"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def make_example(row):\n",
        "    prompt = (\n",
        "        \"From the following information about a ligand, predict whether it can bind to the HIF-2α protein.\\n\\n\"\n",
        "        f\"This ligand is represented by the SMILES string {row['Ligand SMILES']}, and exhibits an IC50 of \"\n",
        "        f\"{row['IC50 (nM)']} nM (pIC50 = {row['pIC50']:.2f}). It has a molecular weight of {row['MolWt']:.2f} Da, \"\n",
        "        f\"a topological polar surface area of {row['TPSA']:.2f} Å², {row['HBD']} hydrogen bond donor\"\n",
        "        f\"{'s' if row['HBD'] != 1 else ''}, {row['HBA']} hydrogen bond acceptor\"\n",
        "        f\"{'s' if row['HBA'] != 1 else ''}, and {row['RotBonds']} rotatable bond\"\n",
        "        f\"{'s' if row['RotBonds'] != 1 else ''}, with a logP of {row['LogP']:.2f}.\\n\"\n",
        "    )\n",
        "    completion = \"Answer: Yes, it binds to HIF-2α<eos>\" if row[\"is_known_binder\"] else \"Answer: No, it doesn't bind to HIF-2α<eos>\"\n",
        "    return {\"prompt\": prompt, \"bind\": completion}\n",
        "\n",
        "\n",
        "with open(\"train_hif_binding.jsonl\",\"w\") as fout:\n",
        "    for _, row in all_binders.iterrows():\n",
        "        ex = make_example(row)\n",
        "        fout.write(json.dumps(ex) + \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}